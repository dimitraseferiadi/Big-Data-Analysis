{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a20aa1e5-7947-4f19-ab91-e9f4b019a864",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>697</td><td>application_1732639283265_0664</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-36.eu-central-1.compute.internal:20888/proxy/application_1732639283265_0664/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-119.eu-central-1.compute.internal:8042/node/containerlogs/container_1732639283265_0664_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+--------------------+\n",
      "|        DIVISION|     #|    average_distance|\n",
      "+----------------+------+--------------------+\n",
      "|        VAN NUYS|148946| 0.02856339903536966|\n",
      "|       HOLLYWOOD|140927|0.020444060380655493|\n",
      "|       SOUTHWEST|133420|0.021628874258637677|\n",
      "|        WILSHIRE|132967| 0.02632706717398016|\n",
      "|         OLYMPIC|119636|0.017338152570481324|\n",
      "| NORTH HOLLYWOOD|118938|  0.0263080120045502|\n",
      "|     77TH STREET|116946|0.016632946064630495|\n",
      "|       SOUTHEAST|105162| 0.02403583311415139|\n",
      "|         PACIFIC|104090|0.037408008860875336|\n",
      "|         TOPANGA|103828| 0.03233359516748025|\n",
      "|         RAMPART| 95479|0.014934307019218239|\n",
      "|         CENTRAL| 93531|0.009495482667801518|\n",
      "|     WEST VALLEY| 90132|0.028989371552462475|\n",
      "|          HARBOR| 88268| 0.03480036440117154|\n",
      "|        FOOTHILL| 87497|0.041252498599392944|\n",
      "|      HOLLENBECK| 81541|0.026781603358714202|\n",
      "|WEST LOS ANGELES| 79670|0.030343153555294662|\n",
      "|         MISSION| 78753|0.035104180437474056|\n",
      "|       NORTHEAST| 75180| 0.03924676071240839|\n",
      "|          NEWTON| 73844|  0.0158407012281438|\n",
      "+----------------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Time taken: 22.57 seconds"
     ]
    }
   ],
   "source": [
    "from sedona.spark import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, avg, count, desc\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "import time\n",
    "\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Query 5 - Crime Analysis with Police Stations\") \\\n",
    "    .config(\"spark.executor.instances\", \"2\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.cores\", \"4\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Create Sedona context\n",
    "sedona = SedonaContext.create(spark)\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Load datasets\n",
    "crime_data = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv\", header=True)\n",
    "station_data = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/LA_Police_Stations.csv\", header=True)\n",
    "\n",
    "# Filter out Null Island records and create geometries for crime data\n",
    "crime_data = crime_data.filter((col(\"LAT\").isNotNull()) & (col(\"LON\").isNotNull()) & (col(\"LAT\") != 0) & (col(\"LON\") != 0))\n",
    "crime_data = crime_data.withColumn(\"crime_geometry\", ST_Point(col(\"LON\").cast(\"double\"), col(\"LAT\").cast(\"double\")))\n",
    "\n",
    "# Create geometries for police stations using X and Y columns\n",
    "station_data = station_data.filter((col(\"X\").isNotNull()) & (col(\"Y\").isNotNull()))\n",
    "station_data = station_data.withColumn(\"station_geometry\", ST_Point(col(\"X\").cast(\"double\"), col(\"Y\").cast(\"double\")))\n",
    "\n",
    "# Broadcast police stations for join efficiency\n",
    "station_data_broadcast = station_data.select(\"station_geometry\", \"DIVISION\").alias(\"stations\")\n",
    "\n",
    "# Join crime data with police stations to calculate distances\n",
    "crime_with_distances = crime_data.crossJoin(station_data_broadcast) \\\n",
    "    .withColumn(\"distance\", ST_Distance(col(\"crime_geometry\"), col(\"stations.station_geometry\")))\n",
    "\n",
    "# Find the closest station for each crime using DR_NO as the unique identifier\n",
    "window_spec = Window.partitionBy(\"DR_NO\").orderBy(col(\"distance\").asc())\n",
    "closest_station = crime_with_distances.withColumn(\"row_number\", row_number().over(window_spec)) \\\n",
    "    .filter(col(\"row_number\") == 1) \\\n",
    "    .select(\"DR_NO\", \"DIVISION\", \"distance\")\n",
    "\n",
    "# Aggregate results by station\n",
    "results = closest_station.groupBy(\"DIVISION\").agg(\n",
    "    count(\"DR_NO\").alias(\"#\"),\n",
    "    avg(\"distance\").alias(\"average_distance\")\n",
    ")\n",
    "\n",
    "# Sort results by number of incidents\n",
    "sorted_results = results.orderBy(desc(\"#\"))\n",
    "\n",
    "# Display the results\n",
    "sorted_results.show()\n",
    "\n",
    "# Stop timing and print out the execution duration\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "# Stop Spark session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ee4ecb2-4935-493c-ae06-88a009773820",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>698</td><td>application_1732639283265_0665</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-36.eu-central-1.compute.internal:20888/proxy/application_1732639283265_0665/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-16.eu-central-1.compute.internal:8042/node/containerlogs/container_1732639283265_0665_01_000002/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+--------------------+\n",
      "|        DIVISION|     #|    average_distance|\n",
      "+----------------+------+--------------------+\n",
      "|        VAN NUYS|148946| 0.02856339903536965|\n",
      "|       HOLLYWOOD|140927| 0.02044406038065549|\n",
      "|       SOUTHWEST|133420| 0.02162887425863768|\n",
      "|        WILSHIRE|132967|0.026327067173980156|\n",
      "|         OLYMPIC|119636|0.017338152570481328|\n",
      "| NORTH HOLLYWOOD|118938|0.026308012004550196|\n",
      "|     77TH STREET|116946|  0.0166329460646305|\n",
      "|       SOUTHEAST|105162| 0.02403583311415139|\n",
      "|         PACIFIC|104090|0.037408008860875315|\n",
      "|         TOPANGA|103828| 0.03233359516748025|\n",
      "|         RAMPART| 95479|0.014934307019218239|\n",
      "|         CENTRAL| 93531|0.009495482667801515|\n",
      "|     WEST VALLEY| 90132|0.028989371552462475|\n",
      "|          HARBOR| 88268|0.034800364401171534|\n",
      "|        FOOTHILL| 87497| 0.04125249859939294|\n",
      "|      HOLLENBECK| 81541|  0.0267816033587142|\n",
      "|WEST LOS ANGELES| 79670| 0.03034315355529467|\n",
      "|         MISSION| 78753| 0.03510418043747406|\n",
      "|       NORTHEAST| 75180| 0.03924676071240839|\n",
      "|          NEWTON| 73844|0.015840701228143794|\n",
      "+----------------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Time taken: 25.06 seconds"
     ]
    }
   ],
   "source": [
    "from sedona.spark import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, avg, count, desc\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "import time\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Query 5 - Crime Analysis with Police Stations\") \\\n",
    "    .config(\"spark.executor.instances\", \"4\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.cores\", \"2\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Create Sedona context\n",
    "sedona = SedonaContext.create(spark)\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Load datasets\n",
    "crime_data = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv\", header=True)\n",
    "station_data = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/LA_Police_Stations.csv\", header=True)\n",
    "\n",
    "# Filter out Null Island records and create geometries for crime data\n",
    "crime_data = crime_data.filter((col(\"LAT\").isNotNull()) & (col(\"LON\").isNotNull()) & (col(\"LAT\") != 0) & (col(\"LON\") != 0))\n",
    "crime_data = crime_data.withColumn(\"crime_geometry\", ST_Point(col(\"LON\").cast(\"double\"), col(\"LAT\").cast(\"double\")))\n",
    "\n",
    "# Create geometries for police stations using X and Y columns\n",
    "station_data = station_data.filter((col(\"X\").isNotNull()) & (col(\"Y\").isNotNull()))\n",
    "station_data = station_data.withColumn(\"station_geometry\", ST_Point(col(\"X\").cast(\"double\"), col(\"Y\").cast(\"double\")))\n",
    "\n",
    "# Broadcast police stations for join efficiency\n",
    "station_data_broadcast = station_data.select(\"station_geometry\", \"DIVISION\").alias(\"stations\")\n",
    "\n",
    "# Join crime data with police stations to calculate distances\n",
    "crime_with_distances = crime_data.crossJoin(station_data_broadcast) \\\n",
    "    .withColumn(\"distance\", ST_Distance(col(\"crime_geometry\"), col(\"stations.station_geometry\")))\n",
    "\n",
    "# Find the closest station for each crime using DR_NO as the unique identifier\n",
    "window_spec = Window.partitionBy(\"DR_NO\").orderBy(col(\"distance\").asc())\n",
    "closest_station = crime_with_distances.withColumn(\"row_number\", row_number().over(window_spec)) \\\n",
    "    .filter(col(\"row_number\") == 1) \\\n",
    "    .select(\"DR_NO\", \"DIVISION\", \"distance\")\n",
    "\n",
    "# Aggregate results by station\n",
    "results = closest_station.groupBy(\"DIVISION\").agg(\n",
    "    count(\"DR_NO\").alias(\"#\"),\n",
    "    avg(\"distance\").alias(\"average_distance\")\n",
    ")\n",
    "\n",
    "# Sort results by number of incidents\n",
    "sorted_results = results.orderBy(desc(\"#\"))\n",
    "\n",
    "# Display the results\n",
    "sorted_results.show()\n",
    "\n",
    "# Stop timing and print out the execution duration\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "# Stop Spark session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f090512a-e29e-4e7a-9abe-5102b0a10bfc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>700</td><td>application_1732639283265_0667</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-36.eu-central-1.compute.internal:20888/proxy/application_1732639283265_0667/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-181.eu-central-1.compute.internal:8042/node/containerlogs/container_1732639283265_0667_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+--------------------+\n",
      "|        DIVISION|     #|    average_distance|\n",
      "+----------------+------+--------------------+\n",
      "|        VAN NUYS|148946| 0.02856339903536965|\n",
      "|       HOLLYWOOD|140927| 0.02044406038065549|\n",
      "|       SOUTHWEST|133420|0.021628874258637673|\n",
      "|        WILSHIRE|132967|0.026327067173980152|\n",
      "|         OLYMPIC|119636|0.017338152570481328|\n",
      "| NORTH HOLLYWOOD|118938|0.026308012004550196|\n",
      "|     77TH STREET|116946|  0.0166329460646305|\n",
      "|       SOUTHEAST|105162|0.024035833114151393|\n",
      "|         PACIFIC|104090| 0.03740800886087533|\n",
      "|         TOPANGA|103828| 0.03233359516748025|\n",
      "|         RAMPART| 95479|0.014934307019218237|\n",
      "|         CENTRAL| 93531|0.009495482667801518|\n",
      "|     WEST VALLEY| 90132| 0.02898937155246247|\n",
      "|          HARBOR| 88268| 0.03480036440117154|\n",
      "|        FOOTHILL| 87497| 0.04125249859939293|\n",
      "|      HOLLENBECK| 81541| 0.02678160335871419|\n",
      "|WEST LOS ANGELES| 79670|0.030343153555294662|\n",
      "|         MISSION| 78753| 0.03510418043747406|\n",
      "|       NORTHEAST| 75180| 0.03924676071240839|\n",
      "|          NEWTON| 73844|  0.0158407012281438|\n",
      "+----------------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Time taken: 22.14 seconds"
     ]
    }
   ],
   "source": [
    "from sedona.spark import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, avg, count, desc\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "import time\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Query 5 - Crime Analysis with Police Stations\") \\\n",
    "    .config(\"spark.executor.instances\", \"8\") \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .config(\"spark.executor.cores\", \"1\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Create Sedona context\n",
    "sedona = SedonaContext.create(spark)\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Load datasets\n",
    "crime_data = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv\", header=True)\n",
    "station_data = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/LA_Police_Stations.csv\", header=True)\n",
    "\n",
    "# Filter out Null Island records and create geometries for crime data\n",
    "crime_data = crime_data.filter((col(\"LAT\").isNotNull()) & (col(\"LON\").isNotNull()) & (col(\"LAT\") != 0) & (col(\"LON\") != 0))\n",
    "crime_data = crime_data.withColumn(\"crime_geometry\", ST_Point(col(\"LON\").cast(\"double\"), col(\"LAT\").cast(\"double\")))\n",
    "\n",
    "# Create geometries for police stations using X and Y columns\n",
    "station_data = station_data.filter((col(\"X\").isNotNull()) & (col(\"Y\").isNotNull()))\n",
    "station_data = station_data.withColumn(\"station_geometry\", ST_Point(col(\"X\").cast(\"double\"), col(\"Y\").cast(\"double\")))\n",
    "\n",
    "# Broadcast police stations for join efficiency\n",
    "station_data_broadcast = station_data.select(\"station_geometry\", \"DIVISION\").alias(\"stations\")\n",
    "\n",
    "# Join crime data with police stations to calculate distances\n",
    "crime_with_distances = crime_data.crossJoin(station_data_broadcast) \\\n",
    "    .withColumn(\"distance\", ST_Distance(col(\"crime_geometry\"), col(\"stations.station_geometry\")))\n",
    "\n",
    "# Find the closest station for each crime using DR_NO as the unique identifier\n",
    "window_spec = Window.partitionBy(\"DR_NO\").orderBy(col(\"distance\").asc())\n",
    "closest_station = crime_with_distances.withColumn(\"row_number\", row_number().over(window_spec)) \\\n",
    "    .filter(col(\"row_number\") == 1) \\\n",
    "    .select(\"DR_NO\", \"DIVISION\", \"distance\")\n",
    "\n",
    "# Aggregate results by station\n",
    "results = closest_station.groupBy(\"DIVISION\").agg(\n",
    "    count(\"DR_NO\").alias(\"#\"),\n",
    "    avg(\"distance\").alias(\"average_distance\")\n",
    ")\n",
    "\n",
    "# Sort results by number of incidents\n",
    "sorted_results = results.orderBy(desc(\"#\"))\n",
    "\n",
    "# Display the results\n",
    "sorted_results.show()\n",
    "\n",
    "# Stop timing and print out the execution duration\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "# Stop Spark session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d9b3c8-88d0-4858-bba6-a48df6ee5473",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
